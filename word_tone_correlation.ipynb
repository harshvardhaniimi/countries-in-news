{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.5 GiB for an array with shape (50000, 49784) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 32\u001b[0m\n\u001b[0;32m     29\u001b[0m word_matrix \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Create a DataFrame from the word matrix\u001b[39;00m\n\u001b[1;32m---> 32\u001b[0m word_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mword_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtoarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m, columns\u001b[38;5;241m=\u001b[39mvectorizer\u001b[38;5;241m.\u001b[39mget_feature_names_out())\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Add avg_tone column to the word matrix DataFrame\u001b[39;00m\n\u001b[0;32m     35\u001b[0m word_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvgTone\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvgTone\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[1;32mc:\\Users\\kmaro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1050\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_toarray_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\kmaro\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\sparse\\_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 18.5 GiB for an array with shape (50000, 49784) and data type int64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from urllib.parse import urlparse, unquote\n",
    "import re\n",
    "from collections import defaultdict\n",
    "\n",
    "df = pd.read_csv('gdelt-2024-11-20-000000000000.csv')[['AvgTone', 'SOURCEURL']]\n",
    "\n",
    "# Grab only 400 rows for testing\n",
    "df = df.head(50000)\n",
    "\n",
    "# Extract article names from URLs\n",
    "def extract_article_name(url):\n",
    "    parsed = urlparse(url)\n",
    "    path = unquote(parsed.path)  # Decode URL-encoded characters\n",
    "    return re.sub(r'[-_]', ' ', path.split('/')[-1])  # Replace '-' and '_' with spaces\n",
    "\n",
    "df['article_name'] = df['SOURCEURL'].apply(extract_article_name)\n",
    "\n",
    "# Tokenize article names into words\n",
    "df['words'] = df['article_name'].apply(lambda x: re.findall(r'\\b\\w+\\b', x.lower()))\n",
    "\n",
    "# Create a word-document matrix (binary occurrence matrix)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Join words for each article\n",
    "df['text'] = df['words'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "word_matrix = vectorizer.fit_transform(df['text'])\n",
    "\n",
    "# Create a DataFrame from the word matrix\n",
    "word_df = pd.DataFrame(word_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Add avg_tone column to the word matrix DataFrame\n",
    "word_df['AvgTone'] = df['AvgTone'].values\n",
    "\n",
    "# Calculate correlations between each word and avg_tone\n",
    "correlations = {}\n",
    "for word in word_df.columns[:-1]:  # Exclude avg_tone\n",
    "    correlations[word] = word_df[word].corr(word_df['AvgTone'])\n",
    "\n",
    "# Convert correlations to a sorted DataFrame\n",
    "correlation_df = pd.DataFrame(list(correlations.items()), columns=['word', 'correlation']).sort_values(\n",
    "    by='correlation', ascending=False\n",
    ")\n",
    "\n",
    "# Create a easy to read table for top and bottom 20 words\n",
    "top_words = correlation_df.head(20)\n",
    "bottom_words = correlation_df.tail(20)[::-1]\n",
    "\n",
    "print(top_words)\n",
    "print(bottom_words)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
